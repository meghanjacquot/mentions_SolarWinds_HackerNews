{"cells":[{"metadata":{},"cell_type":"markdown","source":"We can use this dataset about HackerNews to query with BigQuery word frequency about articles about topics. I was thinking about how SolarWinds appeared in the past compared to how it is appearing now (note we will need a new dataset to make the second query).  Let's find out using the BigQuery Hacker News dataset! I'll use the BigQuery Python client library to query the stories table of the hacker_news dataset where title contains solarWinds or SolarWinds.\n\nBefore I begin, note that in total size, the Hacker News BigQuery dataset is 14GB which is larger than most Kaggle Datasets (the file upload limit is 10GB uncompressed). It's not big in BigQuery terms, but it's still a good idea for me to avoid using SELECT * statements so that I don't query more than necessary against my 5TB monthly free quota.\n\nLet's get started!"},{"metadata":{"_cell_guid":"8464cfa7-dace-4b24-a064-24b570764005","_uuid":"042afa3aa6498110232976c35393ea1d95a02c36","trusted":true},"cell_type":"code","source":"from google.cloud import bigquery\nimport pandas as pd\n\n\n\nclient = bigquery.Client()\n\n# Using WHERE reduces the amount of data scanned / quota used\nquery = \"\"\"\nSELECT title, time_ts\nFROM `bigquery-public-data.hacker_news.stories`\nWHERE REGEXP_CONTAINS(title, r\"(s|S)olarWinds\")\nORDER BY time\n\"\"\"\n\nquery_job = client.query(query)\n\niterator = query_job.result(timeout=30)\nrows = list(iterator)\n\n# Transform the rows into a nice pandas dataframe\nheadlines = pd.DataFrame(data=[list(x.values()) for x in rows], columns=list(rows[0].keys()))\n\n# Look at the first 10 headlines\nheadlines.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Very cool! It was super quick and easy to pull down this data. A next step would be to **compare mentions of SolarWinds now**...but that will be for later. \n\nAlright, now that the headlines in a nice dataframe, I think the natural next step is to create a word cloud. Let's go ahead and do that and see what stands out."},{"metadata":{"trusted":true,"_uuid":"74c36b464f54b638470b7701c97ec0443aa8786a"},"cell_type":"code","source":"import wordcloud\nimport matplotlib.pyplot as plt\n\nwords = ' '.join(headlines.title).lower()\ncloud = wordcloud.WordCloud(background_color='black',\n                            max_font_size=200,\n                            width=1600,\n                            height=800,\n                            max_words=300,\n                            relative_scaling=.5).generate(words)\nplt.figure(figsize=(20,10))\nplt.axis('off')\nplt.savefig('SolarWinds-hackernews.png')\nplt.imshow(cloud);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Great! Let me know what you think about using the BigQuery Python client libraries to query BigQuery datasets. If you want to try it out yourself, I recommend a few resources:\n\nSohier's \"Getting Started\" kernel will show you the basics plus he shares more about the BigQuery API here.\n\nCheck out these tips for managing resources in BigQuery (so you don't exhaust your 5TB too quickly).\n\nSee all BigQuery datasets that are accessible on Kaggle via Kernels here: https://www.kaggle.com/datasets?filetype=bigQuery"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}